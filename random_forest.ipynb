{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from util import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "# --------------------- > covariance from raw data  imagery and shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_imagery_and_shapes_1750.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_imagery_and_shapes_1750.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "    ],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from raw data only imagery\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_only_imagery_1250.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_only_imagery_1250.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "    ],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from raw data only shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_only_shapes_500.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_only_shapes_500.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "    ],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from frequencies data imagery and shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_frequency_imagery_and_shapes_1750.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "        600,\n",
    "    ],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from frequencies data only imagery\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_only_imagery_1250.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_frequency_only_imagery_1250.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "        600,\n",
    "    ],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "\n",
    "# --------------------- > covariance from frequencies data only shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_only_shapes_500.csv\",\n",
    "    \"result_dataset_url\": \"./results/randomForest/rf_covariance_frequency_only_shapes_500.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"random_forest_estimators\": [\n",
    "        5,\n",
    "        10,\n",
    "        15,\n",
    "        20,\n",
    "        25,\n",
    "        30,\n",
    "        35,\n",
    "        40,\n",
    "        50,\n",
    "        55,\n",
    "        80,\n",
    "        100,\n",
    "        150,\n",
    "        200,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "        600,\n",
    "    ],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_url):\n",
    "    df = pd.read_csv(dataset_url)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    df.head()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_data_to_values(value_string):\n",
    "  str_list = np.array(json.loads(value_string))\n",
    "  return str_list\n",
    "\n",
    "def convert_dataset(dataset,cols):\n",
    "  df = dataset.copy()\n",
    "  for col in cols:\n",
    "    df[col] = df[col].apply(convert_string_data_to_values)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, subject,label):\n",
    "    test_dataset = dataset.copy()\n",
    "    test_dataset = test_dataset[test_dataset['subject'] == subject]\n",
    "    test_dataset['label'] = test_dataset['label'].apply(lambda x: label if x == label else 'Imagery')\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(X,y,k):\n",
    "    # k is number of top features to select\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(dataset, data_cols,n_estimators = 30, k=20):\n",
    "    df = dataset.copy()\n",
    "    le = preprocessing.LabelEncoder()  # Generates a look-up table\n",
    "    le.fit(df.loc[:, \"label\"])\n",
    "    df[\"label\"] = le.transform(df[\"label\"])\n",
    "\n",
    "    X = []\n",
    "    for channels in df[data_cols].values:\n",
    "        scaled_channels = []\n",
    "        for c in channels:\n",
    "            scaled_channels.append(c.reshape(-1, 1))\n",
    "        X.append(scaled_channels)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = [i for i in df[\"label\"]]\n",
    "\n",
    "    X = feature_extract(X, y, k)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    RFC = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    RFC.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = RFC.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:5 and estimators: 5 is 83.01564350436533\n",
      "\n",
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:10 and estimators: 5 is 83.14935690875542\n",
      "\n",
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:20 and estimators: 5 is 83.8452587512738\n",
      "\n",
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:50 and estimators: 5 is 84.24281858492388\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:5 and estimators: 5 is 83.14116334793029\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:10 and estimators: 5 is 83.44418739155583\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:20 and estimators: 5 is 84.27118620727644\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:5 and estimators: 5 is 82.61952333380903\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:10 and estimators: 5 is 83.77467770324914\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:20 and estimators: 5 is 84.22577422577424\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:50 and estimators: 5 is 84.32400932400932\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:5 and estimators: 5 is 82.30548899721835\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:10 and estimators: 5 is 83.97924756947313\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:20 and estimators: 5 is 84.76989176237295\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:100 and estimators: 5 is 84.8326172574293\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:150 and estimators: 5 is 84.86367016442208\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:200 and estimators: 5 is 84.92928750447548\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:5 and estimators: 5 is 82.82354237241455\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:10 and estimators: 5 is 84.27607480239061\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:20 and estimators: 5 is 84.90147070974139\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:100 and estimators: 5 is 85.13068385248837\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:5 and estimators: 5 is 83.36699015270446\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:10 and estimators: 5 is 84.04595404595406\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:20 and estimators: 5 is 84.33590219304504\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:50 and estimators: 5 is 84.86905951191665\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:150 and estimators: 5 is 85.17518196089625\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:300 and estimators: 5 is 85.42517006802723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df = read_dataset(dataset_url=dataset[\"dataset_url\"])\n",
    "    df = convert_dataset(dataset=df, cols=dataset[\"data_cols\"])\n",
    "\n",
    "    subjects = df[\"subject\"].unique()\n",
    "    labels = df[\"label\"].unique()\n",
    "    max_avg_total = 0\n",
    "    final_accuracies = {}\n",
    "    for feature_extract_k in dataset[\"feature_extract_arg_k\"]:\n",
    "        for estimators in dataset[\"random_forest_estimators\"]:\n",
    "            accuracies = {}\n",
    "            avg_total = 0\n",
    "            labels_accuracies = {}\n",
    "            for subject in subjects:\n",
    "                accuracies[subject] = {}\n",
    "                avg = 0\n",
    "                for label in labels:\n",
    "                    if not label in labels_accuracies:\n",
    "                        labels_accuracies[label] = 0\n",
    "\n",
    "                    # main part is here other is just for computing accuracies\n",
    "                    temp_dataset = split_dataset(df, subject, label)\n",
    "                    acc = calc_accuracy(\n",
    "                        temp_dataset,\n",
    "                        dataset[\"data_cols\"],\n",
    "                        n_estimators=estimators,\n",
    "                        k=feature_extract_k,\n",
    "                    )\n",
    "                    acc = calc_accuracy(\n",
    "                        temp_dataset,\n",
    "                        dataset[\"data_cols\"],\n",
    "                        k=feature_extract_k,\n",
    "                    )\n",
    "\n",
    "                    accuracies[subject][label] = acc\n",
    "                    labels_accuracies[label] += acc\n",
    "                    avg += acc\n",
    "                    avg_total += acc\n",
    "\n",
    "                avg = avg / len(labels)\n",
    "                accuracies[subject][\"avg\"] = avg * 100\n",
    "\n",
    "            avg_total = avg_total / (len(subjects) * len(labels))\n",
    "            if max_avg_total < avg_total:\n",
    "                max_avg_total = avg_total\n",
    "                labels_accuracies = {\n",
    "                    key: value / len(subjects) for key, value in labels_accuracies.items()\n",
    "                }\n",
    "\n",
    "                print(\n",
    "                    f\"Total Average for { dataset['dataset_url'] } with k:{feature_extract_k} and estimators: {estimators} is {avg_total*100}\"\n",
    "                )\n",
    "                print()\n",
    "\n",
    "                accuracies[\"avg_total\"] = {}\n",
    "                accuracies[\"k\"] = {\"avg\": feature_extract_k}\n",
    "                accuracies[\"estimators\"] = {\"avg\": estimators}\n",
    "                for key, lAcc in labels_accuracies.items():\n",
    "                    accuracies[\"avg_total\"][key] = lAcc\n",
    "                accuracies[\"avg_total\"][\"avg\"] = avg_total * 100\n",
    "\n",
    "                final_accuracies = accuracies\n",
    "\n",
    "    os.makedirs(os.path.dirname(dataset[\"result_dataset_url\"]), exist_ok=True)\n",
    "    pd.DataFrame(final_accuracies).to_csv(dataset[\"result_dataset_url\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

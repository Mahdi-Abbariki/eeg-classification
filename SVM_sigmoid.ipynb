{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from util import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "# --------------------- > covariance from raw data  imagery and shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_imagery_and_shapes_1750.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_imagery_and_shapes_1750.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from raw data only imagery\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_only_imagery_1250.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_only_imagery_1250.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from raw data only shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-raw/covariance_only_shapes_500.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_only_shapes_500.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50],\n",
    "    \"data_cols\": Constants.data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from frequencies data imagery and shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_frequency_imagery_and_shapes_1750.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "# --------------------- > covariance from frequencies data only imagery\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_only_imagery_1250.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_frequency_only_imagery_1250.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)\n",
    "\n",
    "\n",
    "# --------------------- > covariance from frequencies data only shapes\n",
    "ddict = {\n",
    "    \"dataset_url\": \"./cov-freq/covariance_frequency_only_shapes_500.csv\",\n",
    "    \"result_dataset_url\": \"./results/svm/sigmoid/svm_covariance_frequency_only_shapes_500.csv\",\n",
    "    \"feature_extract_arg_k\": [5, 10, 20, 50, 100, 150, 180, 200, 250, 300, 500],\n",
    "    \"data_cols\": Constants.frequency_data_columns,\n",
    "}\n",
    "datasets.append(ddict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_url):\n",
    "    df = pd.read_csv(dataset_url)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    df.head()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_data_to_values(value_string):\n",
    "  str_list = np.array(json.loads(value_string))\n",
    "  return str_list\n",
    "\n",
    "def convert_dataset(dataset,cols):\n",
    "  df = dataset.copy()\n",
    "  for col in cols:\n",
    "    df[col] = df[col].apply(convert_string_data_to_values)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, subject,label):\n",
    "    test_dataset = dataset.copy()\n",
    "    test_dataset = test_dataset[test_dataset['subject'] == subject]\n",
    "    test_dataset['label'] = test_dataset['label'].apply(lambda x: label if x == label else 'Imagery')\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(X,y,k):\n",
    "    # k is number of top features to select\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(dataset, data_cols, k=20):\n",
    "    df = dataset.copy()\n",
    "    le = preprocessing.LabelEncoder()  # Generates a look-up table\n",
    "    le.fit(df.loc[:, \"label\"])\n",
    "    df[\"label\"] = le.transform(df[\"label\"])\n",
    "\n",
    "    X = []\n",
    "    for channels in df[data_cols].values:\n",
    "        scaled_channels = []\n",
    "        for c in channels:\n",
    "            scaled_channels.append(c.reshape(-1, 1))\n",
    "        X.append(scaled_channels)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = [i for i in df[\"label\"]]\n",
    "\n",
    "    X = feature_extract(X, y, k)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \"\"\"\n",
    "    the smaller the nu is, the higher accuracies get\n",
    "    \"\"\"\n",
    "    SVC = svm.NuSVC(kernel=\"sigmoid\", gamma=\"scale\", nu=0.01)\n",
    "    SVC.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = SVC.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:5 is 43.099369302376815\n",
      "\n",
      "Total Average for ./cov-raw/covariance_imagery_and_shapes_1750.csv with k:50 is 44.806246385193745\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:5 is 43.85152441543419\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:10 is 47.224241923490034\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_imagery_1250.csv with k:50 is 47.68259935553168\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:5 is 39.382641168355455\n",
      "\n",
      "Total Average for ./cov-raw/covariance_only_shapes_500.csv with k:50 is 43.932615004043576\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_imagery_and_shapes_1750.csv with k:5 is 54.033297529538125\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:5 is 45.23919689333223\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:10 is 47.40787408080641\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:20 is 47.71922939216171\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_imagery_1250.csv with k:180 is 49.63011925417942\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:5 is 42.94943152086009\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:50 is 45.327648541934266\n",
      "\n",
      "Total Average for ./cov-freq/covariance_frequency_only_shapes_500.csv with k:300 is 46.5271633128776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    df = read_dataset(dataset_url=dataset[\"dataset_url\"])\n",
    "    df = convert_dataset(dataset=df, cols=dataset[\"data_cols\"])\n",
    "\n",
    "    subjects = df[\"subject\"].unique()\n",
    "    labels = df[\"label\"].unique()\n",
    "    max_avg_total = 0\n",
    "    final_accuracies = {}\n",
    "    for feature_extract_k in dataset[\"feature_extract_arg_k\"]:\n",
    "        accuracies = {}\n",
    "        avg_total = 0\n",
    "        labels_accuracies = {}\n",
    "        for subject in subjects:\n",
    "            accuracies[subject] = {}\n",
    "            avg = 0\n",
    "            for label in labels:\n",
    "                if not label in labels_accuracies:\n",
    "                    labels_accuracies[label] = 0\n",
    "\n",
    "                # main part is here other is just for computing accuracies\n",
    "                temp_dataset = split_dataset(df, subject, label)\n",
    "                acc = calc_accuracy(\n",
    "                    temp_dataset,\n",
    "                    dataset[\"data_cols\"],\n",
    "                    k=feature_extract_k,\n",
    "                )\n",
    "\n",
    "                accuracies[subject][label] = acc\n",
    "                labels_accuracies[label] += acc\n",
    "                avg += acc\n",
    "                avg_total += acc\n",
    "\n",
    "            avg = avg / len(labels)\n",
    "            accuracies[subject][\"avg\"] = avg * 100\n",
    "\n",
    "        avg_total = avg_total / (len(subjects) * len(labels))\n",
    "        if max_avg_total < avg_total:\n",
    "            max_avg_total = avg_total\n",
    "            labels_accuracies = {\n",
    "                key: value / len(subjects) for key, value in labels_accuracies.items()\n",
    "            }\n",
    "\n",
    "            print(\n",
    "                f\"Total Average for { dataset['dataset_url'] } with k:{feature_extract_k} is {avg_total*100}\"\n",
    "            )\n",
    "            print()\n",
    "\n",
    "            accuracies[\"avg_total\"] = {}\n",
    "            accuracies[\"k\"] = {\"avg\": feature_extract_k}\n",
    "            for key, lAcc in labels_accuracies.items():\n",
    "                accuracies[\"avg_total\"][key] = lAcc\n",
    "            accuracies[\"avg_total\"][\"avg\"] = avg_total * 100\n",
    "\n",
    "            final_accuracies = accuracies\n",
    "\n",
    "    os.makedirs(os.path.dirname(dataset[\"result_dataset_url\"]), exist_ok=True)\n",
    "    pd.DataFrame(final_accuracies).to_csv(dataset[\"result_dataset_url\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
